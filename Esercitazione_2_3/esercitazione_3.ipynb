{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T10:06:48.730820Z",
     "start_time": "2025-09-06T10:06:48.712319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import wordnet as wn\n",
    "from googletrans import Translator\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "import string\n",
    "import pandas as pd"
   ],
   "id": "466bd4a663e1e70e",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T10:06:48.750434Z",
     "start_time": "2025-09-06T10:06:48.747317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import deepl\n",
    "\n",
    "DEEPL_API_KEY = \"2d6ad839-652e-439a-9086-91e97200d4a8:fx\"\n",
    "\n",
    "\n",
    "def traduci_definizioni():\n",
    "    translator = deepl.Translator(DEEPL_API_KEY)\n",
    "    definitions = pd.read_csv(\"data/definizioni_column.csv\")\n",
    "    columns = definitions.columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "    traslated_df = []\n",
    "    for index, row in definitions.iterrows():\n",
    "        new_row = []\n",
    "        for defition in row:\n",
    "            if defition == \"nan\":\n",
    "                new_row.append(\"nan\")\n",
    "                continue\n",
    "\n",
    "            translated = translator.translate_text(defition, target_lang=\"EN-US\", source_lang=\"IT\")\n",
    "            new_row.append(translated.text)\n",
    "        traslated_df.append(new_row)\n",
    "\n",
    "    new_df = pd.DataFrame(traslated_df, columns=columns)\n",
    "    new_df.to_csv(\"data/definizioni_column_en_2.csv\", index=False)\n",
    "\n",
    "\n",
    "#traduci_definizioni()\n"
   ],
   "id": "57218540e0661941",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T10:06:48.763230Z",
     "start_time": "2025-09-06T10:06:48.759443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_k_genus(definitions, k=1):\n",
    "\n",
    "    defintions_tokens = []\n",
    "    stop_words = stopwords.words('english')\n",
    "    for definition in definitions:\n",
    "        tokens =  word_tokenize(definition.lower())\n",
    "        tokens = [token for token in tokens if token not in stop_words and token not in string.punctuation]\n",
    "        defintions_tokens.append(tokens)\n",
    "\n",
    "    # count the frequency of the tokens\n",
    "    genus_counts = {}\n",
    "    for tokens in defintions_tokens:\n",
    "        for token in tokens:\n",
    "            if token in genus_counts:\n",
    "                genus_counts[token] += 1\n",
    "            else:\n",
    "                genus_counts[token] = 1\n",
    "\n",
    "    sorted_genus_counts = sorted(genus_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    genus_to_return = [genus[0] for genus in sorted_genus_counts[:k]]\n",
    "\n",
    "    return genus_to_return\n",
    "\n",
    "def load_embeddings(embeddings_path):\n",
    "    # load the embedding space from the file\n",
    "\n",
    "    data = np.load(embeddings_path, allow_pickle=True)\n",
    "    embeddings = data['embeddings']\n",
    "    synset_names = data['synsets']\n",
    "\n",
    "    # create a dict [Synset: Definition]\n",
    "    synsets_embeddings = dict(zip(synset_names, embeddings))\n",
    "\n",
    "    return synsets_embeddings\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize and convert to lowercase\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and token not in string.punctuation]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n"
   ],
   "id": "5c4fdbe605416ad8",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T10:06:48.776338Z",
     "start_time": "2025-09-06T10:06:48.772212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "definitions = pd.read_csv(\"data/definizioni_column_en_2.csv\")\n",
    "\n",
    "categoria = \"Pantalone[CG]\"\n",
    "concetto = \"trouser.n.01\"\n",
    "\n"
   ],
   "id": "7d328dfec68658a5",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**CONTENT TO FORM USING WORDNET**",
   "id": "ad20dc182ee7ad0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T10:06:49.018060Z",
     "start_time": "2025-09-06T10:06:48.783810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def onomasiological_by_word_freq(definitions, k=1):\n",
    "    # get the possible genus for the definitions\n",
    "    genus = get_k_genus(definitions, 1)\n",
    "\n",
    "    print(f\"The genus are: {genus}\")\n",
    "    # build the possibile synset set\n",
    "\n",
    "    # set of the synsets associated to the genus\n",
    "    genus_synsets = set()\n",
    "\n",
    "    # add the genus synsets and it's lemmas\n",
    "    for genus_name in genus:\n",
    "        for current_synset in wn.synsets(genus_name):\n",
    "            genus_synsets.add(current_synset)\n",
    "            for current_lemma in current_synset.lemmas():\n",
    "                genus_synsets.add(current_lemma)\n",
    "\n",
    "    # build the set of genus hyponyms (where the research will be)\n",
    "    possible_synsets = set()\n",
    "\n",
    "    for genus_synset in genus_synsets:\n",
    "        for hyponym in genus_synset.hyponyms():\n",
    "            possible_synsets.add(hyponym)\n",
    "\n",
    "    # list of (DEFINITION_ID, POSSIBLE_SYNSETS)\n",
    "    results = []\n",
    "\n",
    "    for index, definition in enumerate(definitions):\n",
    "        definition_tokens = preprocess_text(definition).split(\" \")\n",
    "\n",
    "        synset_similarities = []\n",
    "\n",
    "        for possible_synset in possible_synsets:\n",
    "            synsets_tokens = preprocess_text(possible_synset.definition()).split(\" \")\n",
    "\n",
    "            intersection = set(definition_tokens).intersection(synsets_tokens)\n",
    "            union = set(definition_tokens).union(synsets_tokens)\n",
    "\n",
    "            similarity = len(intersection)/len(union)\n",
    "\n",
    "            synset_similarities.append((similarity, possible_synset))\n",
    "\n",
    "        synset_similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "        best_synsets = [synset for similarity, synset in synset_similarities[:k]]\n",
    "\n",
    "        results.append((index+1, best_synsets))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "results = onomasiological_by_word_freq(definitions[categoria], k=4)\n",
    "correct_synset = wn.synset(concetto)\n",
    "\n",
    "results_table = PrettyTable(field_names=[\"Definition ID\", \"Synsets\", \"Correct\"])\n",
    "\n",
    "correct_count = 0\n",
    "for result in results:\n",
    "    if correct_synset in result[1]:\n",
    "        correct_count += 1\n",
    "        correct = True\n",
    "    else:\n",
    "        correct = False\n",
    "    row = [f\"P{result[0]}\", result[1], correct]\n",
    "    results_table.add_row(row)\n",
    "\n",
    "\n",
    "print(f\"Correct synset guessed: {correct_count}/{len(results)}\")\n",
    "\n",
    "print(results_table)\n",
    "\n"
   ],
   "id": "fcb5b49c4d138d6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The genus are: ['garment']\n",
      "Correct synset guessed: 11/39\n",
      "+---------------+------------------------------------------------------------------------------------------------------------+---------+\n",
      "| Definition ID |                                                  Synsets                                                   | Correct |\n",
      "+---------------+------------------------------------------------------------------------------------------------------------+---------+\n",
      "|       P1      |       [Synset('sweater.n.01'), Synset('trouser.n.02'), Synset('shirt.n.01'), Synset('romper.n.02')]        |  False  |\n",
      "|       P2      |      [Synset('camlet.n.01'), Synset('sunsuit.n.01'), Synset('legging.n.01'), Synset('trouser.n.01')]       |   True  |\n",
      "|       P3      |    [Synset('gown.v.01'), Synset('prim.v.03'), Synset('overgarment.n.01'), Synset('undergarment.n.01')]     |  False  |\n",
      "|       P4      |   [Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('legging.n.01'), Synset('robe.n.01')]   |  False  |\n",
      "|       P5      |  [Synset('sweater.n.01'), Synset('shirt.n.01'), Synset('overgarment.n.01'), Synset('undergarment.n.01')]   |  False  |\n",
      "|       P6      | [Synset('sweater.n.01'), Synset('legging.n.01'), Synset('head_covering.n.01'), Synset('breechcloth.n.01')] |  False  |\n",
      "|       P7      | [Synset('sweater.n.01'), Synset('legging.n.01'), Synset('head_covering.n.01'), Synset('breechcloth.n.01')] |  False  |\n",
      "|       P8      |    [Synset('silks.n.01'), Synset('hand-me-down.n.01'), Synset('suit.n.01'), Synset('overgarment.n.01')]    |  False  |\n",
      "|       P9      |  [Synset('legging.n.01'), Synset('head_covering.n.01'), Synset('hose.n.02'), Synset('breechcloth.n.01')]   |  False  |\n",
      "|      P10      |  [Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('skirt.n.02'), Synset('separate.n.02')]  |  False  |\n",
      "|      P11      |       [Synset('sweater.n.01'), Synset('trouser.n.02'), Synset('shirt.n.01'), Synset('romper.n.02')]        |  False  |\n",
      "|      P12      |   [Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('legging.n.01'), Synset('hose.n.02')]   |  False  |\n",
      "|      P13      |   [Synset('legging.n.01'), Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('robe.n.01')]   |  False  |\n",
      "|      P14      | [Synset('legging.n.01'), Synset('head_covering.n.01'), Synset('breechcloth.n.01'), Synset('trouser.n.01')] |   True  |\n",
      "|      P15      | [Synset('neckwear.n.01'), Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('diaper.n.01')]  |  False  |\n",
      "|      P16      |       [Synset('sweater.n.01'), Synset('trouser.n.02'), Synset('shirt.n.01'), Synset('romper.n.02')]        |  False  |\n",
      "|      P17      |  [Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('separate.n.02'), Synset('shirt.n.01')]  |  False  |\n",
      "|      P18      |         [Synset('cover.v.26'), Synset('camlet.n.01'), Synset('gown.n.04'), Synset('legging.n.01')]         |  False  |\n",
      "|      P19      |       [Synset('scapular.n.02'), Synset('sweater.n.01'), Synset('romper.n.02'), Synset('haik.n.01')]        |  False  |\n",
      "|      P20      |        [Synset('cover.v.26'), Synset('ironing.n.01'), Synset('neckwear.n.01'), Synset('vest.v.05')]        |  False  |\n",
      "|      P21      |   [Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('legging.n.01'), Synset('robe.n.01')]   |  False  |\n",
      "|      P22      |  [Synset('shirt.n.01'), Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('sweater.n.01')]   |  False  |\n",
      "|      P23      | [Synset('legging.n.01'), Synset('head_covering.n.01'), Synset('breechcloth.n.01'), Synset('trouser.n.01')] |   True  |\n",
      "|      P24      |   [Synset('cover.v.26'), Synset('head_covering.n.01'), Synset('ironing.n.01'), Synset('neckwear.n.01')]    |  False  |\n",
      "|      P25      |   [Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('robe.n.01'), Synset('mending.n.01')]   |  False  |\n",
      "|      P26      | [Synset('legging.n.01'), Synset('head_covering.n.01'), Synset('breechcloth.n.01'), Synset('trouser.n.01')] |   True  |\n",
      "|      P27      | [Synset('legging.n.01'), Synset('head_covering.n.01'), Synset('breechcloth.n.01'), Synset('trouser.n.01')] |   True  |\n",
      "|      P28      |   [Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('legging.n.01'), Synset('robe.n.01')]   |  False  |\n",
      "|      P29      | [Synset('legging.n.01'), Synset('head_covering.n.01'), Synset('breechcloth.n.01'), Synset('trouser.n.01')] |   True  |\n",
      "|      P30      |    [Synset('trouser.n.01'), Synset('camlet.n.01'), Synset('breechcloth.n.01'), Synset('separate.n.02')]    |   True  |\n",
      "|      P31      |        [Synset('trouser.n.01'), Synset('shirt.n.01'), Synset('sweater.n.01'), Synset('skirt.n.02')]        |   True  |\n",
      "|      P32      |  [Synset('trouser.n.02'), Synset('shirt.n.01'), Synset('overgarment.n.01'), Synset('undergarment.n.01')]   |  False  |\n",
      "|      P33      |   [Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('robe.n.01'), Synset('mending.n.01')]   |  False  |\n",
      "|      P34      |       [Synset('camlet.n.01'), Synset('legging.n.01'), Synset('trouser.n.01'), Synset('diaper.n.01')]       |   True  |\n",
      "|      P35      |   [Synset('camlet.n.01'), Synset('skirt.n.02'), Synset('overgarment.n.01'), Synset('undergarment.n.01')]   |  False  |\n",
      "|      P36      |  [Synset('shirt.n.01'), Synset('sweater.n.01'), Synset('overgarment.n.01'), Synset('undergarment.n.01')]   |  False  |\n",
      "|      P37      | [Synset('legging.n.01'), Synset('head_covering.n.01'), Synset('breechcloth.n.01'), Synset('trouser.n.01')] |   True  |\n",
      "|      P38      |         [Synset('trouser.n.01'), Synset('hose.n.02'), Synset('legging.n.01'), Synset('gown.v.01')]         |   True  |\n",
      "|      P39      |  [Synset('shirt.n.01'), Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('sweater.n.01')]   |  False  |\n",
      "+---------------+------------------------------------------------------------------------------------------------------------+---------+\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**CONTENT TO FORM: Sentence Embeddings**",
   "id": "64100141071b9a7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T10:06:49.853501Z",
     "start_time": "2025-09-06T10:06:49.031254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def onomasiological_by_sentence_embeddings(definitions, k=1):\n",
    "\n",
    "    # get the possibile genus for the definitions\n",
    "    genus = get_k_genus(definitions, 1)\n",
    "\n",
    "\n",
    "    print(f\"The genus are: {genus}\")\n",
    "    # build the possibile synset set\n",
    "\n",
    "    # set of the synsets associated to the genus\n",
    "    genus_synsets = set()\n",
    "\n",
    "    # add the genus synsets and it's lemmas\n",
    "    for genus_name in genus:\n",
    "        for current_synset in wn.synsets(genus_name):\n",
    "            genus_synsets.add(current_synset)\n",
    "            for current_lemma in current_synset.lemmas():\n",
    "                genus_synsets.add(current_lemma)\n",
    "\n",
    "    # build the set of genus hyponyms (where the research will be)\n",
    "    possible_synsets = set()\n",
    "\n",
    "    for genus_synset in genus_synsets:\n",
    "        for hyponym in genus_synset.hyponyms():\n",
    "            possible_synsets.add(hyponym)\n",
    "\n",
    "\n",
    "    # get the synset description\n",
    "\n",
    "    synsets_tokens = {}\n",
    "    for synset in possible_synsets:\n",
    "        synset_signature = synset.definition()\n",
    "        synsets_tokens[synset.name()] = synset_signature\n",
    "\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "\n",
    "    model = SentenceTransformer(\"thenlper/gte-small\", cache_folder=\"model\", local_files_only = True)\n",
    "\n",
    "    synsets_embeddings = model.encode(list(synsets_tokens.values()), show_progress_bar=True, random_state=42)\n",
    "\n",
    "    #cleaned_definitions = [preprocess_text(definition) for definition in definitions['Pantalone[CG]'] ]\n",
    "\n",
    "    definitions_embeddings = model.encode(definitions , show_progress_bar=True, random_state=42)\n",
    "\n",
    "\n",
    "    # get the synset embeddings and definition most similar\n",
    "    similarities = cosine_similarity(definitions_embeddings, synsets_embeddings)\n",
    "\n",
    "    # list of (DEFINITION_ID, POSSIBLE_SYNSETS)\n",
    "    results = []\n",
    "\n",
    "    for def_index, row in enumerate(similarities):\n",
    "        index = np.argsort(row)[::-1]\n",
    "        best_k_index = index[:k]\n",
    "\n",
    "        best_synsets = []\n",
    "        for index in best_k_index:\n",
    "            tmp_synset = wn.synset(list(synsets_tokens.keys())[index])\n",
    "            best_synsets.append(tmp_synset)\n",
    "\n",
    "        results.append((def_index+1, best_synsets))\n",
    "\n",
    "    return results\n",
    "\n",
    "results = onomasiological_by_sentence_embeddings(definitions[categoria], k=4)\n",
    "\n",
    "correct_synset = wn.synset(concetto)\n",
    "\n",
    "results_table = PrettyTable(field_names=[\"Definition ID\", \"Synsets\", \"Correct\"])\n",
    "\n",
    "correct_count = 0\n",
    "for result in results:\n",
    "    if correct_synset in result[1]:\n",
    "        correct_count += 1\n",
    "        correct = True\n",
    "    else:\n",
    "        correct = False\n",
    "    row = [f\"P{result[0]}\", result[1], correct]\n",
    "    results_table.add_row(row)\n",
    "\n",
    "\n",
    "print(f\"Correct synset guessed: {correct_count}/{len(results)}\")\n",
    "\n",
    "print(results_table)\n",
    "\n",
    "\n"
   ],
   "id": "940403de212def1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The genus are: ['garment']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:00<00:00, 14.63it/s]\n",
      "Batches: 100%|██████████| 2/2 [00:00<00:00, 65.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct synset guessed: 21/39\n",
      "+---------------+------------------------------------------------------------------------------------------------------------+---------+\n",
      "| Definition ID |                                                  Synsets                                                   | Correct |\n",
      "+---------------+------------------------------------------------------------------------------------------------------------+---------+\n",
      "|       P1      | [Synset('shirt.n.01'), Synset('undergarment.n.01'), Synset('sweater.n.01'), Synset('head_covering.n.01')]  |  False  |\n",
      "|       P2      |   [Synset('trouser.n.01'), Synset('legging.n.01'), Synset('separate.n.02'), Synset('overgarment.n.01')]    |   True  |\n",
      "|       P3      |      [Synset('legging.n.01'), Synset('overgarment.n.01'), Synset('shirt.n.01'), Synset('weeds.n.01')]      |  False  |\n",
      "|       P4      |    [Synset('legging.n.01'), Synset('trouser.n.01'), Synset('overgarment.n.01'), Synset('camlet.n.01')]     |   True  |\n",
      "|       P5      |     [Synset('shirt.n.01'), Synset('legging.n.01'), Synset('trouser.n.01'), Synset('overgarment.n.01')]     |   True  |\n",
      "|       P6      |       [Synset('legging.n.01'), Synset('trouser.n.01'), Synset('shirt.n.01'), Synset('leotard.n.01')]       |   True  |\n",
      "|       P7      |   [Synset('legging.n.01'), Synset('trouser.n.01'), Synset('overgarment.n.01'), Synset('separate.n.02')]    |   True  |\n",
      "|       P8      |  [Synset('overgarment.n.01'), Synset('separate.n.02'), Synset('undergarment.n.01'), Synset('shirt.n.01')]  |  False  |\n",
      "|       P9      | [Synset('legging.n.01'), Synset('head_covering.n.01'), Synset('overgarment.n.01'), Synset('trouser.n.01')] |   True  |\n",
      "|      P10      |  [Synset('skirt.n.02'), Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('trouser.n.02')]   |  False  |\n",
      "|      P11      |  [Synset('shirt.n.01'), Synset('undergarment.n.01'), Synset('overgarment.n.01'), Synset('separate.n.02')]  |  False  |\n",
      "|      P12      | [Synset('legging.n.01'), Synset('overgarment.n.01'), Synset('trouser.n.01'), Synset('undergarment.n.01')]  |   True  |\n",
      "|      P13      |    [Synset('legging.n.01'), Synset('trouser.n.01'), Synset('overgarment.n.01'), Synset('trouser.n.02')]    |   True  |\n",
      "|      P14      | [Synset('legging.n.01'), Synset('breechcloth.n.01'), Synset('trouser.n.01'), Synset('head_covering.n.01')] |   True  |\n",
      "|      P15      |     [Synset('legging.n.01'), Synset('overgarment.n.01'), Synset('trouser.n.01'), Synset('hose.n.02')]      |   True  |\n",
      "|      P16      |  [Synset('shirt.n.01'), Synset('undergarment.n.01'), Synset('overgarment.n.01'), Synset('separate.n.02')]  |  False  |\n",
      "|      P17      |  [Synset('overgarment.n.01'), Synset('legging.n.01'), Synset('shirt.n.01'), Synset('undergarment.n.01')]   |  False  |\n",
      "|      P18      |     [Synset('breechcloth.n.01'), Synset('legging.n.01'), Synset('gown.n.04'), Synset('trouser.n.01')]      |   True  |\n",
      "|      P19      |      [Synset('breechcloth.n.01'), Synset('cover.v.26'), Synset('sweater.n.01'), Synset('scarf.n.01')]      |  False  |\n",
      "|      P20      |    [Synset('shirt.n.01'), Synset('undergarment.n.01'), Synset('legging.n.01'), Synset('trouser.n.01')]     |   True  |\n",
      "|      P21      |    [Synset('legging.n.01'), Synset('trouser.n.01'), Synset('overgarment.n.01'), Synset('trouser.n.02')]    |   True  |\n",
      "|      P22      |  [Synset('shirt.n.01'), Synset('undergarment.n.01'), Synset('overgarment.n.01'), Synset('sweater.n.01')]   |  False  |\n",
      "|      P23      | [Synset('legging.n.01'), Synset('breechcloth.n.01'), Synset('trouser.n.01'), Synset('head_covering.n.01')] |   True  |\n",
      "|      P24      |     [Synset('head_covering.n.01'), Synset('legging.n.01'), Synset('shirt.n.01'), Synset('hose.n.02')]      |  False  |\n",
      "|      P25      |  [Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('trouser.n.02'), Synset('camlet.n.01')]  |  False  |\n",
      "|      P26      |   [Synset('legging.n.01'), Synset('breechcloth.n.01'), Synset('overgarment.n.01'), Synset('shirt.n.01')]   |  False  |\n",
      "|      P27      | [Synset('legging.n.01'), Synset('breechcloth.n.01'), Synset('trouser.n.01'), Synset('head_covering.n.01')] |   True  |\n",
      "|      P28      |    [Synset('legging.n.01'), Synset('trouser.n.01'), Synset('overgarment.n.01'), Synset('camlet.n.01')]     |   True  |\n",
      "|      P29      | [Synset('legging.n.01'), Synset('head_covering.n.01'), Synset('breechcloth.n.01'), Synset('trouser.n.01')] |   True  |\n",
      "|      P30      |    [Synset('undergarment.n.01'), Synset('separate.n.02'), Synset('legging.n.01'), Synset('shirt.n.01')]    |  False  |\n",
      "|      P31      |       [Synset('legging.n.01'), Synset('trouser.n.01'), Synset('skirt.n.02'), Synset('leotard.n.01')]       |   True  |\n",
      "|      P32      |  [Synset('shirt.n.01'), Synset('undergarment.n.01'), Synset('overgarment.n.01'), Synset('trouser.n.02')]   |  False  |\n",
      "|      P33      | [Synset('overgarment.n.01'), Synset('separate.n.02'), Synset('undergarment.n.01'), Synset('camlet.n.01')]  |  False  |\n",
      "|      P34      |    [Synset('legging.n.01'), Synset('overgarment.n.01'), Synset('trouser.n.01'), Synset('camlet.n.01')]     |   True  |\n",
      "|      P35      |    [Synset('overgarment.n.01'), Synset('separate.n.02'), Synset('skirt.n.02'), Synset('trouser.n.02')]     |  False  |\n",
      "|      P36      |  [Synset('shirt.n.01'), Synset('undergarment.n.01'), Synset('overgarment.n.01'), Synset('separate.n.02')]  |  False  |\n",
      "|      P37      | [Synset('legging.n.01'), Synset('breechcloth.n.01'), Synset('trouser.n.01'), Synset('head_covering.n.01')] |   True  |\n",
      "|      P38      |       [Synset('trouser.n.01'), Synset('legging.n.01'), Synset('skirt.n.02'), Synset('leotard.n.01')]       |   True  |\n",
      "|      P39      |  [Synset('shirt.n.01'), Synset('undergarment.n.01'), Synset('overgarment.n.01'), Synset('sweater.n.01')]   |  False  |\n",
      "+---------------+------------------------------------------------------------------------------------------------------------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**GLOBAL EMBEDDINGS**",
   "id": "e3965f409bf79c9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T10:06:51.188867Z",
     "start_time": "2025-09-06T10:06:49.862923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def global_onomasiological_by_sentence_embeddings(definitions, k=1):\n",
    "\n",
    "\n",
    "    embeddings_path = \"./data/embeddings.npz\"\n",
    "\n",
    "    embeddings = load_embeddings(embeddings_path)\n",
    "\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "    model = SentenceTransformer(\"thenlper/gte-small\", cache_folder=\"model\", local_files_only = True)\n",
    "\n",
    "    #cleaned_definitions = [preprocess_text(definition) for definition in definitions]\n",
    "\n",
    "    definitions_embeddings = model.encode(definitions , show_progress_bar=True, random_state=42)\n",
    "\n",
    "\n",
    "    # get the synset embeddings and definition most similar\n",
    "    similarities = cosine_similarity(definitions_embeddings, list(embeddings.values()))\n",
    "\n",
    "    # list of (DEFINITION_ID, POSSIBLE_SYNSETS)\n",
    "    results = []\n",
    "\n",
    "    for def_index, row in enumerate(similarities):\n",
    "        index = np.argsort(row)[::-1]\n",
    "        best_k_index = index[:k]\n",
    "\n",
    "        best_synsets = []\n",
    "        for index in best_k_index:\n",
    "            tmp_synset = wn.synset(list(embeddings.keys())[index])\n",
    "            best_synsets.append(tmp_synset)\n",
    "\n",
    "        results.append((def_index+1, best_synsets))\n",
    "\n",
    "    return results\n",
    "\n",
    "results = global_onomasiological_by_sentence_embeddings(definitions[categoria], k=4)\n",
    "\n",
    "correct_synset = wn.synset(concetto)\n",
    "\n",
    "results_table = PrettyTable(field_names=[\"Definition ID\", \"Synsets\", \"Correct\"])\n",
    "\n",
    "correct_count = 0\n",
    "for result in results:\n",
    "    if correct_synset in result[1]:\n",
    "        correct_count += 1\n",
    "        correct = True\n",
    "    else:\n",
    "        correct = False\n",
    "    row = [f\"P{result[0]}\", result[1], correct]\n",
    "    results_table.add_row(row)\n",
    "\n",
    "\n",
    "print(f\"Correct synset guessed: {correct_count}/{len(results)}\")\n",
    "\n",
    "print(results_table)\n",
    "\n",
    "\n"
   ],
   "id": "342b7564bdf90ab5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:00<00:00, 69.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct synset guessed: 3/39\n",
      "+---------------+-----------------------------------------------------------------------------------------------------------------------+---------+\n",
      "| Definition ID |                                                        Synsets                                                        | Correct |\n",
      "+---------------+-----------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|       P1      |                [Synset('shirt.n.01'), Synset('person.n.02'), Synset('back.n.07'), Synset('skirt.n.01')]               |  False  |\n",
      "|       P2      |          [Synset('trouser.n.01'), Synset('legging.n.01'), Synset('leg.n.07'), Synset('piece_of_cloth.n.01')]          |   True  |\n",
      "|       P3      |         [Synset('cross-legged.r.01'), Synset('barelegged.s.01'), Synset('kirtle.n.02'), Synset('bodice.n.01')]        |  False  |\n",
      "|       P4      |            [Synset('legging.n.01'), Synset('pant_leg.n.01'), Synset('barelegged.s.01'), Synset('leg.n.07')]           |  False  |\n",
      "|       P5      |                [Synset('shirt.n.01'), Synset('legging.n.01'), Synset('lap.n.03'), Synset('back.n.07')]                |  False  |\n",
      "|       P6      |                [Synset('lap.n.03'), Synset('legging.n.01'), Synset('back.n.07'), Synset('skirt.n.01')]                |  False  |\n",
      "|       P7      |                [Synset('legging.n.01'), Synset('trouser.n.01'), Synset('leg.n.07'), Synset('lap.n.03')]               |   True  |\n",
      "|       P8      |        [Synset('blue.n.02'), Synset('fitter.n.01'), Synset('bluecoat.n.01'), Synset('protective_garment.n.01')]       |  False  |\n",
      "|       P9      |              [Synset('leg.n.07'), Synset('legging.n.01'), Synset('lap.n.03'), Synset('barelegged.s.01')]              |  False  |\n",
      "|      P10      |             [Synset('skirt.n.02'), Synset('skirt.n.01'), Synset('overgarment.n.01'), Synset('apron.n.01')]            |  False  |\n",
      "|      P11      |          [Synset('shirt.n.01'), Synset('get_down.v.01'), Synset('person.n.02'), Synset('undergarment.n.01')]          |  False  |\n",
      "|      P12      |              [Synset('legging.n.01'), Synset('leg.n.07'), Synset('overgarment.n.01'), Synset('lap.n.03')]             |  False  |\n",
      "|      P13      |              [Synset('legging.n.01'), Synset('pant_leg.n.01'), Synset('leg.n.07'), Synset('gaiter.n.03')]             |  False  |\n",
      "|      P14      |              [Synset('barelegged.s.01'), Synset('legging.n.01'), Synset('lap.n.03'), Synset('leg.n.07')]              |  False  |\n",
      "|      P15      |         [Synset('barelegged.s.01'), Synset('wear.v.09'), Synset('legging.n.01'), Synset('bell-bottomed.s.01')]        |  False  |\n",
      "|      P16      |          [Synset('shirt.n.01'), Synset('get_down.v.01'), Synset('person.n.02'), Synset('undergarment.n.01')]          |  False  |\n",
      "|      P17      |         [Synset('overgarment.n.01'), Synset('legging.n.01'), Synset('barelegged.s.01'), Synset('shirt.n.01')]         |  False  |\n",
      "|      P18      |       [Synset('barelegged.s.01'), Synset('skirt.n.01'), Synset('undercut.n.01'), Synset('skirt_of_tasses.n.01')]      |  False  |\n",
      "|      P19      |              [Synset('skirt.n.01'), Synset('person.n.02'), Synset('dressing.n.04'), Synset('seat.n.09')]              |  False  |\n",
      "|      P20      |              [Synset('get_down.v.01'), Synset('person.n.02'), Synset('wear.v.09'), Synset('skirt.n.01')]              |  False  |\n",
      "|      P21      |            [Synset('legging.n.01'), Synset('pant_leg.n.01'), Synset('barelegged.s.01'), Synset('leg.n.07')]           |  False  |\n",
      "|      P22      |           [Synset('shirt.n.01'), Synset('get_down.v.01'), Synset('back.n.07'), Synset('undergarment.n.01')]           |  False  |\n",
      "|      P23      |              [Synset('barelegged.s.01'), Synset('legging.n.01'), Synset('lap.n.03'), Synset('leg.n.07')]              |  False  |\n",
      "|      P24      |       [Synset('headdress.n.01'), Synset('barelegged.s.01'), Synset('head_covering.n.01'), Synset('person.n.02')]      |  False  |\n",
      "|      P25      | [Synset('overgarment.n.01'), Synset('undergarment.n.01'), Synset('right-side-out.s.01'), Synset('garmentmaker.n.01')] |  False  |\n",
      "|      P26      |              [Synset('legging.n.01'), Synset('lap.n.03'), Synset('barelegged.s.01'), Synset('leg.n.07')]              |  False  |\n",
      "|      P27      |              [Synset('barelegged.s.01'), Synset('legging.n.01'), Synset('lap.n.03'), Synset('leg.n.07')]              |  False  |\n",
      "|      P28      |            [Synset('legging.n.01'), Synset('pant_leg.n.01'), Synset('barelegged.s.01'), Synset('leg.n.07')]           |  False  |\n",
      "|      P29      |              [Synset('barelegged.s.01'), Synset('legging.n.01'), Synset('lap.n.03'), Synset('leg.n.07')]              |  False  |\n",
      "|      P30      |  [Synset('piece_of_cloth.n.01'), Synset('undergarment.n.01'), Synset('separate.n.02'), Synset('bell-bottomed.s.01')]  |  False  |\n",
      "|      P31      |               [Synset('legging.n.01'), Synset('trouser.n.01'), Synset('top.n.10'), Synset('skirt.n.01')]              |   True  |\n",
      "|      P32      |             [Synset('shirt.n.01'), Synset('undergarment.n.01'), Synset('skirt.n.01'), Synset('back.n.07')]            |  False  |\n",
      "|      P33      |           [Synset('gabardine.n.01'), Synset('coverall.n.01'), Synset('nankeen.n.01'), Synset('levi's.n.01')]          |  False  |\n",
      "|      P34      |             [Synset('nylon.n.02'), Synset('acrylic.n.04'), Synset('barelegged.s.01'), Synset('lap.n.03')]             |  False  |\n",
      "|      P35      |            [Synset('skirt.n.01'), Synset('top.n.10'), Synset('overgarment.n.01'), Synset('separate.n.02')]            |  False  |\n",
      "|      P36      |           [Synset('shirt.n.01'), Synset('undergarment.n.01'), Synset('wear.v.09'), Synset('coverall.n.01')]           |  False  |\n",
      "|      P37      |              [Synset('barelegged.s.01'), Synset('legging.n.01'), Synset('lap.n.03'), Synset('leg.n.07')]              |  False  |\n",
      "|      P38      |                [Synset('lap.n.03'), Synset('leg.n.07'), Synset('barelegged.s.01'), Synset('spat.n.02')]               |  False  |\n",
      "|      P39      |           [Synset('shirt.n.01'), Synset('undergarment.n.01'), Synset('get_down.v.01'), Synset('back.n.07')]           |  False  |\n",
      "+---------------+-----------------------------------------------------------------------------------------------------------------------+---------+\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T10:06:51.201341Z",
     "start_time": "2025-09-06T10:06:51.199450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "tmp = wn.synset(\"trouser.n.01\")\n",
    "\n",
    "print(tmp.definition())\n",
    "\n"
   ],
   "id": "3f64f25a3db1b11f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(usually in the plural) a garment extending from the waist to the knee or ankle, covering each leg separately\n"
     ]
    }
   ],
   "execution_count": 58
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
